---
layout: single
title: "[논문리뷰]Stacked Hourglass Networks for Human Pose Estimation"
excerpt: "arXiv:1603.06937v2 [cs.CV] 26 Jul 2016"
categories: HPE
tag: [Human Pose Estimation, Hourglass]
use_math: true
---

2D image 기반의 Human Pose Estimation에서  Feature Extractor으로 가장 많이 사용하고 있는 ***Hourglass Network***대해 논문리뷰를 해보려고 한다. 

지금은 3D HPE 연구가 활발히 진행되고 있지만, Human Pose를 이해하기 위해서 [이 논문](https://arxiv.org/abs/1603.06937)을 공부하는 것은 필연적이라고 생각한다.

사실 이전에도 읽었지만, 딥러닝과 수학적인 지식이 부족한 터라 이해하기 쉽지 않았다. 그동안 기초를 다지며 이 논문을 반드시 이해하리라 다짐했다. 그럼 논문리뷰를 시작하도록 한다!



![image-20220331201742790](https://raw.githubusercontent.com/kjw9899/kjw9899.github.io/master/kjw9899/kjw9899.github.io/assets/images/image-20220331201742790.png)



> **Abstract**

* 2016년 당시, Human Pose Estimation 분야에서 새로운 Network 구조였다.
* bottom-up 방식과 top-down 방식의 결합으로 all scales에서 feature extraction이 가능하다.

*  Hourglass Network의 사용하여, MPII dataset에서 대략 2%의 정확도 상승 효과를 보았고 추정하기 더 어려운 관절인 무릎과 발목에서 4-5%의 정확도 상승 효과를 보았다.

* Hourglass Network는 오로지 RGB Image의 single person's pose의 관절 추정에만 초점을 맞췄다.



대략적인 Hourglass Network에 대한 요약은 여기서 끝내고 Network의 구조에 대해서 살펴보도록하자.



## Network Architecture

![image-20220331222141899](https://raw.githubusercontent.com/kjw9899/kjw9899.github.io/master/kjw9899/kjw9899.github.io/assets/images/image-20220331222141899.png)

### (1) Hourglass Design

이미지 내의 사람의 자세에 대한 정보를  <span style='background-color: #fff5b1'>모든 scale</span>에서 추정하는 것이 굉장히 필요하다. 또한 얼굴이나 손처럼 지역적인 정보 또한 중요하게 다뤄야한다.

어떤 논문들은 모델 파이프라인을 분해해서 학습한 뒤 후에 결합하는 방식을 사용했지만,<span style='background-color: #fff5b1'> Hourglass Network는 매우 단순하고 공간적인 정보를 보전하기 위해서 skip layer를 사용한 single pipeline을 사용한다.</span> 

* Feature 추출과 가장 낮은 해상도를 얻기 위해서 Convolutional layer와 maxpooling layer를 사용한다.
* 각 maxpooling 단계에서, 네트워크가 별도로 갈라지며, 원래의 pre-pooled resolution에 convolution 연산을 더 적용한다. 
* 가장 낮은 해상도에 도달한 후, upsampling에 해당하는 top-down 순서를 수행하고 scale 별로 추출한 feature들을 조합한다.
* Hourglass Network는 Tomson의 과정을 따르고 upsampling은 nearest neighbor upsampling을 사용하며 feature들을 조합할 때는 elementwise addition(행렬덧셈)을 사용한다.

* Hourglass Network는 대칭 구조이다.
* output 해상도에 도달하면, 두 번의 연이은 1x1 convolution 연산을 통해 최종적인 prediction을 수행한다.
* 네트워크의 output은 관절이 존재할 확률이 담긴 heatmap이다.



### (2) Layer Implementation

![image-20220331230006689](https://raw.githubusercontent.com/kjw9899/kjw9899.github.io/master/kjw9899/kjw9899.github.io/assets/images/image-20220331230006689.png)

* 최종적으로 디자인으로 Fig.4.Left에 있는 Resudual module의 사용을 극대화했다.
* Filter 크기를 3x3 이상으로 사용하지 않았다.
* Bottlenecking은 각 layer가 축소될 때 전체 parameter 수를 제한한다.
* GPU memory로 인해 input size는 256 x 256
* Start : 7x7 convolutional layer / stride = 2 / maxpooling(256 $\rightarrow$ 64)
* Fig.4.Right를 보면, 두 개의 branch로 나눠지는데, 하나는 heatmap를 생성하고, 그 heatmap에 loss가 더해진다. 
* 1x1 convolution은 채널 중간의 feature들을 match하기 위해서 heatmap을 재배치한다.
* 이전의 hourglass로 부터의 features와 1x1 convolution으로 연산된 features를 하나의 값으로 더한다.



### (3) Stacked Hourglass with Intermediate Supervision

Stacked Hourglass라는 말 그대로 HG의 구조가 end-to-end 형태로 맞물려 있는 형태이다. 하나의 output이 그 다음 input으로 이어지는 형태다.  <span style='background-color: #fff5b1'>이러한 구조는 bottom-up과 top-down 방식의 추론을 반복하면서 재평가의 기능을 갖는다. 이러한 접근의 핵심은 heatmap 중간중간에 손실을 추가해 줄 수 있다는 것이다.</span> 

지역적인 맥락과 전역적인 맥락에서 추출된 feature들을 process할 수 있는 기회를 가지는 각 HG를 통과한 이후에 예측값들이 생성된다. 그 이후의 HG들은 높은 수준의 feature들을 고차원적인 공간적 관계에서 재평가하게 한다. 

만약 Supervision이 upsampling 후에 제공된다면 재평가는 이루어지지 않아서 global context를 반영하지 못 할 것이다. 사람의 관절를 예측하는 데 있어서 전체 이미지의 공간적인 정보 또한 매우 중요하다. 

하지만 Stacked HG는 이러한 걱정을 완화한다. local and global 단서들이 각 HG 모듈 내에서 통합되기 때문이다. 즉 사람의 관절 정보는 사진 내에서 공간적인 정보와 매우 밀접한 관련이 있으므로 이를 보존하는데 탁월한 기능을 수행할 수 있다는 말이다.



### (4) Training Details

* FLIC (5003 images = 3987 training + 1016 testing)
* MPII Human Pose : 25k images, annotations for multiple people (40k =28k training + 11k testing)
* All input image size : 256 x 256
* RMSProp with learning rate 2.5e-4
* Used BatchNormalization

* MSE loss function
* 2D Gaussian

![image-20220401002942343](https://raw.githubusercontent.com/kjw9899/kjw9899.github.io/master/kjw9899/kjw9899.github.io/assets/images/image-20220401002942343.png)

![image-20220401003218925](https://raw.githubusercontent.com/kjw9899/kjw9899.github.io/master/kjw9899/kjw9899.github.io/assets/images/image-20220401003218925.png)



HG를 8개를 쌓았을 때 가장 성능이 뛰어 났다.

































